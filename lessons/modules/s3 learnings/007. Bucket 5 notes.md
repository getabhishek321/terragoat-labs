# Bucket: `aws_s3_bucket.data_science`

## Purpose

The `data_science` bucket is designed to store:

* datasets
* model outputs
* experiment artifacts
* feature-engineering files
* ML-generated insights

Data science workloads typically involve processing **large volumes of sensitive data**, such as:

* customer attributes
* behavioral logs
* marketing datasets
* training inputs

TerraformGoat simulates a challenge scenario here:
This bucket is **better secured** than previous ones, but it still contains a major flaw (**missing encryption**).

---

## Terraform Definition (Simplified)

```hcl
resource "aws_s3_bucket" "data_science" {
  # bucket is not encrypted
  bucket = "${local.resource_prefix.value}-data-science"
  acl    = "private"

  versioning {
    enabled = true
  }

  logging {
    target_bucket = "${aws_s3_bucket.logs.id}"
    target_prefix = "log/"
  }

  force_destroy = true
  tags = { ... }
}
```

---

#  Deep Dive Into Configuration

## **1. `acl = "private"`**

Ensures no public access.
This is the correct default posture for ML/data workloads.

But remember:

> Private ACL ≠ encryption, compliance, or audit readiness.

---

## **2. ✔ Versioning enabled**

```hcl
versioning {
  enabled = true
}
```

This is an important improvement, especially in the ML domain:

### Why versioning matters for Data Science:

* Large datasets may be modified often
* Experiment results must stay reproducible
* Rollback is needed for corruption or failed training
* Critical for compliance when datasets represent regulated customer data
* Useful in investigating tampering or poisoning attacks

Data poisoning attacks (where adversaries inject altered training data) become significantly harder to hide with versioning enabled.

---

## **3. ✔ Access Logging Enabled**

```hcl
logging {
  target_bucket = "${aws_s3_bucket.logs.id}"
  target_prefix = "log/"
}
```

This is a **major upgrade** compared to all earlier buckets.

Meaning:

* Every access to this bucket is logged into the `logs` bucket
* SOC/DFIR teams can analyze access patterns
* Helps detect suspicious model-download or dataset-exfil attempts
* Required by CIS AWS Benchmark

This teaches you how **centralized S3 logging** is supposed to work.

---

## **4. Missing Server-Side Encryption (SSE)**

Despite versioning + logging, the bucket still lacks:

```hcl
server_side_encryption_configuration { ... }
```

This means:

* All ML datasets and artifacts are stored **unencrypted**
* Data breaches can occur even if the bucket is private
* Violates compliance standards for PII-based model training
* Prevents organizations from meeting SOC2, ISO27001, GDPR, HIPAA, etc.

**Why this matters for Data Science buckets:**

* Datasets often contain customer identifiers
* Model artifacts may embed sensitive information (“model inversion” attacks)
* Attackers can abuse plaintext at-rest data to reverse ML logic
* Intellectual property (trained models) is exposed

TerraformGoat intentionally leaves this gap to teach:

> Even buckets with *good security controls* can be non-compliant if encryption is missing.

---

## **5. `force_destroy = true`**

This makes the bucket easy to delete during labs but dangerous otherwise.

Combined with versioning:

* Deletes the bucket and **all versions of objects**
* Eliminates historical data
* Can break ML reproducibility
* Deletes ML pipelines’ long-term artifacts

---

#  Complete Risk Summary

| Control            | Status      | Security Impact                         |
| ------------------ | ----------- | --------------------------------------- |
| **ACL private**    | ✔           | Prevents public access                  |
| **Versioning**     | ✔           | Protects against corruption & tampering |
| **Access Logging** | ✔           | Enables forensic visibility             |
| **Encryption**     | ❌ Missing   | At-rest data stored plaintext           |
| **force_destroy**  | ❌ Dangerous | Can wipe critical datasets              |

Even though this bucket has two strong security controls (**versioning + logging**), the missing encryption still makes it **non-compliant and vulnerable**.

---

# Learning Takeaway

`data_science` demonstrates that:

* A bucket can look “secure” at first glance
* But still fail compliance checks
* And still expose sensitive data

This bucket is an excellent example of:

###  "Partially hardened but still insecure" infrastructure

This is one of the most common patterns found in cloud security audits.

Most orgs:

* Enable versioning ✔
* Enable logging ✔
* Forget encryption ❌
* Assume “private bucket” solves everything ❌

TerraformGoat teaches you how to detect such gaps immediately.
